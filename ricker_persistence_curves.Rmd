---
title: "ricker_persistence_curves"
output: html_document
---

```{r}
###############################################################################
# 0. Packages, global constants, and file paths
###############################################################################

# Only need readr for CSV I/O and glue for file naming
library(readr)   # read_csv(), write_csv()
library(glue)    # glue() for constructing file names

# ---------------------------------------------------------------------------
# Biological / model thresholds
# ---------------------------------------------------------------------------

EXTINCTION_THRESHOLD <- 500   # if N drops below this at any time → treat as extinct
SURVIVAL_THRESHOLD   <- 2     # minimum N at final year to count as "survived"
K_CAP_FACTOR         <- 1.1   # cap population at 1.1 × K to avoid runaway explosions
TRAJ_YEARS           <- 100   # length (years) of each simulated trajectory

# ---------------------------------------------------------------------------
# Gompertz calibration settings
# ---------------------------------------------------------------------------

SHIFT_CONST       <- 500      # horizontal shift in K (we actually model K - SHIFT_CONST)
P_TARGETS_DEFAULT <- c(0.025, 0.16, 0.5, 0.84, 0.975)         # anchor percentiles
Y_TARGETS_DEFAULT <- seq(0.0025, 0.9975, by = 0.005)         # dense p-grid (0.25–99.75%)

# ---------------------------------------------------------------------------
# Input / output paths
# ---------------------------------------------------------------------------

PATHS <- list(
  # Inputs: allometry-based demographic predictions from previous script
  pred_mammal_rmax   = "Data/Clean/pred_mammal_rmax.csv",   # cols: Mass, r
  pred_bird_rmax     = "Data/Clean/pred_bird_rmax.csv",     # cols: Mass, r
  pred_mammal_sigma  = "Data/Clean/pred_mammal_sigma.csv",  # cols: Mass, sigma
  pred_bird_sigma    = "Data/Clean/pred_bird_sigma.csv",    # cols: Mass, scenario_*

  # Outputs: persistence curves (directories are assumed to exist)
  results_mammals    = "Data/Results/mammals",
  results_birds      = "Data/Results/birds"
)
```

# 1. Load allometry-based r and σ predictions

These were created in the previous Rmd (demographic allometry + ILR). Each file gives the demographic parameters for a 31-point mass grid.

```{r}
###############################################################################
# 1. Load predicted r and σ from allometry
###############################################################################

# Each CSV:
#   - Mammals: Mass, r or sigma
#   - Birds:   Mass, r, and scenario_* columns for σ (ILR-based scenarios)

pred_mammal_rmax_df  <- read_csv(PATHS$pred_mammal_rmax,  show_col_types = FALSE)
pred_bird_rmax_df    <- read_csv(PATHS$pred_bird_rmax,    show_col_types = FALSE)
pred_mammal_sigma_df <- read_csv(PATHS$pred_mammal_sigma, show_col_types = FALSE)
pred_bird_sigma_df   <- read_csv(PATHS$pred_bird_sigma,   show_col_types = FALSE)

# For mammals, we only ever use the vectors of r and sigma (one per mass point)
pred_mammal_rmax  <- pred_mammal_rmax_df$r
pred_mammal_sigma <- pred_mammal_sigma_df$sigma

# For birds, r is a vector, but σ is scenario-specific, so we keep the whole
# pred_bird_sigma_df and select one scenario column at a time later.
pred_bird_rmax <- pred_bird_rmax_df$r
# pred_bird_sigma_df: first column = Mass, remaining columns = scenario_* (per ILR effect)
```

# 2. Stochastic Ricker simulations

Two core pieces:

simulate_trajectory(): simulate a single time series given (r, σ, K).

simulate_survivors(): repeat trajectories and estimate persistence probability.

```{r}
###############################################################################
# 2. Stochastic Ricker simulations
###############################################################################

# ---------------------------------------------------------------------------
# 2.1 Simulate one population trajectory under stochastic Ricker dynamics
# ---------------------------------------------------------------------------
#
# Model:
#   N_{t+1} = N_t * exp( r * (1 - N_t / K) + ε_t )
#   where ε_t ~ Normal(0, σ^2)
#
# Implementation details:
#   - Start at N_0 = K (population at carrying capacity).
#   - If N falls below EXTINCTION_THRESHOLD at any time, fill the rest with 0
#     and stop (quasi-extinction).
#   - If N overshoots K_CAP_FACTOR * K, clamp it to that cap.
#
# Args:
#   r, sigma : intrinsic growth rate and environmental SD
#   K        : carrying capacity
#   years    : number of time steps to simulate (default 100 years)
#
# Returns:
#   Numeric vector of length years + 1 containing N_0, N_1, ..., N_years
simulate_trajectory <- function(r, sigma, K, years = TRAJ_YEARS) {
  # Initialize population at carrying capacity
  N <- K

  # Pre-allocate full trajectory (N_0 through N_years)
  N_traj <- numeric(years + 1)
  N_traj[1] <- N

  # Loop over years 1, 2, ..., years
  for (t in seq_len(years)) {
    # If population has already crashed below threshold, fill remaining slots with 0
    if (N < EXTINCTION_THRESHOLD) {
      N_traj[(t + 1):(years + 1)] <- 0
      break
    }

    # Draw environmental noise: perturb the growth rate on the log scale
    eps <- rnorm(1, mean = 0, sd = sigma)

    # Stochastic Ricker update
    N <- N * exp(r * (1 - N / K) + eps)

    # Avoid extreme explosions by capping N at K_CAP_FACTOR * K
    if (N > K_CAP_FACTOR * K) {
      N <- K_CAP_FACTOR * K
    }

    # Store population size for this time step
    N_traj[t + 1] <- N
  }

  N_traj
}

# ---------------------------------------------------------------------------
# 2.2 Estimate persistence probability at a given K
# ---------------------------------------------------------------------------
#
# Idea:
#   - Repeatedly simulate trajectories under (r, σ, K).
#   - Count how many end with N >= SURVIVAL_THRESHOLD after TRAJ_YEARS.
#   - Return survivors / reps as the persistence probability.
#
# Args:
#   r, sigma : growth parameters
#   K        : carrying capacity
#   reps     : number of trajectories to simulate
#
# Returns:
#   Scalar probability in [0,1]
simulate_survivors <- function(r, sigma, K, reps) {
  survivors <- 0L

  for (i in seq_len(reps)) {
    # Simulate one trajectory and look only at the final population size
    final_N <- tail(simulate_trajectory(r, sigma, K), 1)

    # Count it as a survivor if it ends above the survival threshold
    if (final_N >= SURVIVAL_THRESHOLD) {
      survivors <- survivors + 1L
    }
  }

  survivors / reps
}
```

# 3. Calibration: minimal K for target persistence (bisection)

We now find, for a given (r, σ) and target persistence probability p, the minimal K that achieves P(persist)≥p.

```{r}
###############################################################################
# 3. Calibrate minimal K for target persistence using bisection
###############################################################################

# ---------------------------------------------------------------------------
# 3.1 Find minimal K for a single target persistence p_min
# ---------------------------------------------------------------------------
#
# Strategy:
#   1. Doubling search:
#        - Start with an interval [start_K / 2, start_K].
#        - Double K until persistence(K) >= p_min.
#        - This yields a bracket [lower_K, upper_K] with upper_K "good".
#   2. Bisection:
#        - Repeatedly bisect [lower_K, upper_K] and evaluate at midpoints.
#        - Keep shrinking the interval until its width is ≤ 1% of upper_K.
#
# Args:
#   r, sigma : growth parameters
#   p_min    : target persistence probability (e.g. 0.5)
#   start_K  : initial guess (used to set the first lower/upper bounds)
#   reps     : number of trajectories per persistence estimate
#
# Returns:
#   list(
#     min_K        : approximate minimal K for p_min,
#     max_K_tested : largest K evaluated during the doubling search
#   )
find_min_k <- function(r, sigma, p_min, start_K, reps) {
  # Initial lower bound and book-keeping of the largest K we tried
  lower_K          <- start_K / 2
  highest_K_tested <- lower_K
  upper_K          <- NA_real_

  # ---- Step 1: doubling search to find an upper bound with sufficient persistence
  repeat {
    cur_K <- lower_K * 2
    highest_K_tested <- cur_K

    p_cur <- simulate_survivors(r, sigma, cur_K, reps)

    if (p_cur >= p_min) {
      # We have found an upper bound where persistence is high enough.
      upper_K <- cur_K
      break
    }

    # Otherwise, move the lower bound up and keep searching.
    lower_K <- cur_K
  }

  # ---- Step 2: bisection within [lower_K, upper_K] until relative width is small
  while ((upper_K - lower_K) > 0.01 * upper_K) {  # stop when interval is ≤ 1% of upper_K
    mid_K <- (lower_K + upper_K) / 2
    p_mid <- simulate_survivors(r, sigma, mid_K, reps)

    if (p_mid >= p_min) {
      upper_K <- mid_K
    } else {
      lower_K <- mid_K
    }
  }

  list(
    min_K        = (lower_K + upper_K) / 2,  # midpoint is our approximate minimal K
    max_K_tested = highest_K_tested          # used as a smart starting point for higher p
  )
}

# ---------------------------------------------------------------------------
# 3.2 Calibrate minimal K for multiple target persistence levels
# ---------------------------------------------------------------------------
#
# For a vector of target persistence values p_targets (low → high), we:
#   - start from an initial K guess start_K for the smallest p_targets[1]
#   - for each p_targets[j], call find_min_k()
#   - reuse the max_K_tested from the previous call as the next start_K
#     (because higher target persistence needs larger or similar K)
#
# This yields anchor points (K_j, p_targets[j]) for the Gompertz curve.
#
# Args:
#   r, sigma     : growth parameters
#   p_targets    : numeric vector of target persistence values
#   start_K      : initial guess for p_targets[1]
#   reps_bisect  : number of simulations per persistence estimate
#
# Returns:
#   Numeric vector of minimal Ks of the same length as p_targets
calibrate_gompertz_points <- function(r, sigma, p_targets, start_K, reps_bisect) {
  min_Ks  <- numeric(length(p_targets))
  K_start <- start_K

  for (j in seq_along(p_targets)) {
    res <- find_min_k(
      r       = r,
      sigma   = sigma,
      p_min   = p_targets[j],
      start_K = K_start,
      reps    = reps_bisect
    )

    min_Ks[j] <- res$min_K
    K_start   <- res$max_K_tested  # chain from the largest K we tried last time
  }

  min_Ks
}
```

# 4. Fit a Gompertz curve for persistence vs K

We use the anchor points from step 3 to fit a smooth Gompertz curve, then invert it to get a dense grid of K values that correspond to a dense grid of persistence probabilities.

```{r}
###############################################################################
# 4. Gompertz curve fit for persistence probability vs K
###############################################################################

# ---------------------------------------------------------------------------
# 4.1 Fit Gompertz in log–log space and build a dense K grid
# ---------------------------------------------------------------------------
#
# Gompertz form:
#   y(K) = exp( -a * exp( -b * log(K - SHIFT_CONST) ) )
#
# where:
#   - y is persistence probability in (0,1)
#   - SHIFT_CONST ensures log(K - shift) is well-defined (K > shift)
#
# Steps:
#   1. Shift K by SHIFT_CONST.
#   2. Compute Xt = log(K - SHIFT_CONST) and Yt = log(-log(y)).
#   3. Fit a simple linear model Yt ~ Xt to obtain starting values (a0, b0).
#   4. Try a small grid of (a, b) around (a0, b0) in nls().
#   5. If that fails, try random restarts around (a0, b0).
#   6. Once a fitted (a_hat, b_hat) is obtained, invert the Gompertz:
#        log(K - shift) = (log(a_hat) - log(-log(y_targets))) / b_hat
#      to get a dense vector of K values.
#
# Args:
#   x         : vector of minimal K values (anchor points)
#   y         : vector of corresponding persistence probabilities
#   y_targets : dense vector of persistence values for which we want K
#
# Returns:
#   list(
#     K_seq = numeric vector of K values (same length as y_targets),
#     fit   = the nls model object
#   )
fit_gompertz_curve <- function(x, y, y_targets = Y_TARGETS_DEFAULT) {
  # Shift K by SHIFT_CONST so log(K - shift) is always valid.
  x_shifted <- x - SHIFT_CONST

  # Linearized variables
  Xt <- log(x_shifted)
  Yt <- log(-log(y))

  # Linear model to get initial guesses for a and b
  lm_fit <- lm(Yt ~ Xt)

  a0 <- exp(coef(lm_fit)[1])   # initial a (positive)
  b0 <- -coef(lm_fit)[2]       # initial b (note the minus sign)

  # ------------- Helper: try a single nls fit with given start values -------
  attempt <- function(a_start, b_start, iters) {
    suppressWarnings(
      try(
        nls(
          y ~ exp(-a * exp(-b * log(x_shifted))),
          start     = list(a = a_start, b = b_start),
          algorithm = "port",
          lower     = c(a = 1e-12, b = 1e-12),
          control   = nls.control(warnOnly = TRUE, maxiter = iters)
        ),
        silent = TRUE
      )
    )
  }

  # ------------- 1) Deterministic grid search around (a0, b0) --------------
  a_grid <- a0 * c(0.25, 0.5, 1, 2, 4)
  b_grid <- b0 * c(0.25, 0.5, 1, 2, 4)
  start_grid <- expand.grid(a = a_grid, b = b_grid)

  nls_fit <- NULL
  K_seq   <- NULL

  for (k in seq_len(nrow(start_grid))) {
    fit_try <- attempt(start_grid$a[k], start_grid$b[k], iters = 200)
    if (inherits(fit_try, "try-error")) next

    ci <- fit_try$convInfo
    if (!is.null(ci) && isTRUE(ci$isConv)) {
      pars  <- coef(fit_try)
      a_hat <- unname(pars["a"])
      b_hat <- unname(pars["b"])

      # Invert Gompertz to get K for each target persistence value
      K_seq_try <- exp((log(a_hat) - log(-log(y_targets))) / b_hat) + SHIFT_CONST

      if (!any(is.na(K_seq_try))) {
        nls_fit <- fit_try
        K_seq   <- K_seq_try
        break
      }
    }
  }

  # ------------- 2) Random restarts if the grid search failed --------------
  if (is.null(nls_fit)) {
    set.seed(123)  # reproducible search

    for (j in seq_len(30)) {
      ai <- a0 * exp(runif(1, log(0.1), log(10)))
      bi <- b0 * exp(runif(1, log(0.1), log(10)))

      fit_try <- attempt(ai, bi, iters = 300)
      if (inherits(fit_try, "try-error")) next

      ci <- fit_try$convInfo
      if (!is.null(ci) && isTRUE(ci$isConv)) {
        pars  <- coef(fit_try)
        a_hat <- unname(pars["a"])
        b_hat <- unname(pars["b"])

        K_seq_try <- exp((log(a_hat) - log(-log(y_targets))) / b_hat) + SHIFT_CONST

        if (!any(is.na(K_seq_try))) {
          nls_fit <- fit_try
          K_seq   <- K_seq_try
          break
        }
      }
    }
  }

  # If all attempts fail, stop with an informative message
  if (is.null(nls_fit)) {
    stop("Gompertz fit failed to converge for the given (r, sigma).")
  }

  list(K_seq = K_seq, fit = nls_fit)
}
```

# 5. Main engine: persistence curves over K for all masses

For each mass-grid entry (with its own r and σ), we:

Find minimal K for a handful of target persistence values (anchor points).

Fit Gompertz to those anchors.

Invert Gompertz to get K for a dense set of persistence targets.

Simulate Ricker dynamics at each K to estimate the actual persistence curve.

```{r}
###############################################################################
# 5. Main engine: persistence curves across K for all mass-grid entries
###############################################################################

# analyze_all_persistence()
#
# Args:
#   pred_rmax   : numeric vector of r values (length = number of mass points)
#   pred_sigma  : numeric vector of σ values (same length as pred_rmax)
#   reps_bisect : number of simulations per K during bisection calibration
#   reps_curve  : number of simulations per K when evaluating the final curve
#   p_targets   : (optional) vector of anchor persistence probabilities
#   y_targets   : (optional) dense target persistence values for Gompertz inversion
#   start_K0    : initial K guess for smallest p_targets[1]
#
# Returns:
#   list(
#     starting_pops     = data.frame (rows = y_targets, cols = mass_1, mass_2, ...)
#     persistence_probs = data.frame (same shape, but probabilities)
#   )
analyze_all_persistence <- function(pred_rmax,
                                    pred_sigma,
                                    reps_bisect,
                                    reps_curve,
                                    p_targets = P_TARGETS_DEFAULT,
                                    y_targets = Y_TARGETS_DEFAULT,
                                    start_K0  = 512) {

  n_mass <- length(pred_rmax)   # number of mass-grid entries
  m_K    <- length(y_targets)   # number of K values (same as length of y_targets)

  # Pre-allocate matrices to store K sequences and resulting persistence probs
  starting_mat <- matrix(NA_real_, nrow = m_K, ncol = n_mass)
  persist_mat  <- matrix(NA_real_, nrow = m_K, ncol = n_mass)

  # Loop over each mass-grid index
  for (i in seq_len(n_mass)) {
    cat("Mass index", i, "of", n_mass, "\n")

    r_i     <- pred_rmax[i]
    sigma_i <- pred_sigma[i]

    # 1) Calibrate minimal K values for the chosen anchor persistence levels
    min_Ks <- calibrate_gompertz_points(
      r           = r_i,
      sigma       = sigma_i,
      p_targets   = p_targets,
      start_K     = start_K0,
      reps_bisect = reps_bisect
    )

    # 2) Fit Gompertz curve to (min_Ks, p_targets) and invert it to get K_seq
    gompertz <- fit_gompertz_curve(
      x         = min_Ks,
      y         = p_targets,
      y_targets = y_targets
    )
    K_seq <- gompertz$K_seq

    # 3) For each K in the dense grid, estimate persistence probability
    p_seq <- vapply(
      X         = K_seq,
      FUN       = function(K) simulate_survivors(r_i, sigma_i, K, reps_curve),
      FUN.VALUE = numeric(1)
    )

    starting_mat[, i] <- K_seq
    persist_mat[,  i] <- p_seq
  }

  # Give each column a name mass_1, mass_2, ..., mass_n
  col_names <- paste0("mass_", seq_len(n_mass))

  starting_pops     <- as.data.frame(starting_mat); names(starting_pops)     <- col_names
  persistence_probs <- as.data.frame(persist_mat);  names(persistence_probs) <- col_names

  list(
    starting_pops     = starting_pops,
    persistence_probs = persistence_probs
  )
}
```

# 6. Example usage: birds (multiple σ scenarios) and mammals

These blocks are wrapped in if (FALSE) so they won’t run automatically when knitting. Turn them on (or run line-by-line) when you actually want to run the heavy simulations.

```{r}
###############################################################################
# 6. Example usage: birds and mammals
###############################################################################

# ---------------------------------------------------------------------------
# 6.1 Birds: persistence curves for multiple σ diet combinations
# ---------------------------------------------------------------------------
#
# Each non-Mass column in pred_bird_sigma_df represents a different
# diet-based ILR effect on σ, labelled by its diet combination string
# (e.g. "100_0_0" for Diet_Inv = 100%, Diet_AllPlants = 0%, Diet_VertFishScav = 0%).
# For each combination we:
#   - extract σ across the mass grid,
#   - run analyze_all_persistence(),
#   - save starting_pops and persistence_probs to disk.
if (TRUE) {
  # All σ diet-combination columns (exclude the first column "Mass")
  combo_cols <- names(pred_bird_sigma_df)[-1]

  for (combo in combo_cols) {
    message("Running bird simulations for diet combo: ", combo)

    # Diet-combination-specific σ vector (length = number of mass-grid points)
    pred_bird_sigma <- pred_bird_sigma_df[[combo]]

    # Run the main engine
    out <- analyze_all_persistence(
      pred_rmax   = pred_bird_rmax,
      pred_sigma  = pred_bird_sigma,
      reps_bisect = 50000,   # reps used during K calibration (coarse but robust)
      reps_curve  = 5000     # reps used for the final persistence curves
    )

    starting_pops     <- out$starting_pops
    persistence_probs <- out$persistence_probs

    # Save one pair of CSVs per diet combination (labelled by the combo string)
    write_csv(
      starting_pops,
      file.path(PATHS$results_birds, glue("bird_{combo}_starting_pops.csv"))
    )
    write_csv(
      persistence_probs,
      file.path(PATHS$results_birds, glue("bird_{combo}_persistence_probs.csv"))
    )
  }
}

# ---------------------------------------------------------------------------
# 6.2 Mammals: persistence curves for a single σ model
# ---------------------------------------------------------------------------
#
# For mammals there is a single σ allometry (no ILR scenarios), so we run the
# pipeline only once. Outputs are used by the persistence-curve-fitting script.
if (FALSE) {
  out <- analyze_all_persistence(
    pred_rmax   = pred_mammal_rmax,
    pred_sigma  = pred_mammal_sigma,
    reps_bisect = 100000,
    reps_curve  = 10000
  )

  starting_pops     <- out$starting_pops
  persistence_probs <- out$persistence_probs

  write_csv(
    starting_pops,
    file.path(PATHS$results_mammals, "mammal_starting_pops.csv")
  )
  write_csv(
    persistence_probs,
    file.path(PATHS$results_mammals, "mammal_persistence_probs.csv")
  )
}
```